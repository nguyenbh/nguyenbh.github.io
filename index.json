[{"authors":["admin"],"categories":null,"content":"I am currently a researcher at the Machine Intelligence Technology Lab, DAMO Academy, Alibaba. My main focus is to break the language barriers across the Alibaba ecosystem.\nMy professional career is a mixed of industrial research labs and startups. Previously, I spent 2 years in Textio, a start-up of augmented writing, where I was responsible for machine learning models. I worked for Microsoft on machine learning models in wearable devices such as the HoloLens project. I was a machine translations researcher at SDL. I am actively coaching early stage startups and young engineers in Vietnam.\nSpecialties: machine translation, natural language processing, speech recognition, speaker identification, machine learning, summarization, parsing, morphology, confidence estimation, language modeling.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://nguyenbh.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am currently a researcher at the Machine Intelligence Technology Lab, DAMO Academy, Alibaba. My main focus is to break the language barriers across the Alibaba ecosystem.\nMy professional career is a mixed of industrial research labs and startups. Previously, I spent 2 years in Textio, a start-up of augmented writing, where I was responsible for machine learning models. I worked for Microsoft on machine learning models in wearable devices such as the HoloLens project.","tags":null,"title":"Nguyen Bach","type":"authors"},{"authors":["Nguyen Bach","Fei Huang"],"categories":null,"content":"","date":1568851200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568851200,"objectID":"7651b12fa2f73a9d7817de6d6852bcb8","permalink":"https://nguyenbh.github.io/publication/noisy-bilstm-based-models-for-disfluency-detection/","publishdate":"2019-09-19T00:00:00Z","relpermalink":"/publication/noisy-bilstm-based-models-for-disfluency-detection/","section":"publication","summary":"This paper describes BiLSTM-based models to disfluency detection in speech transcripts using residual BiLSTM blocks, self-attention, and noisy training approach. Our best model not only surpasses BERT in 4 non-Switchboard test sets, but also is 20 times smaller than the BERT-based model. Thus, we demonstrate that strong performance can be achieved without extensively use of very large training data. In addition, we show that it is possible to be robust across data sets with noisy training approach in which we found insertion is the most useful noise for augmenting training data.","tags":null,"title":"Noisy BiLSTM-Based Models for Disfluency Detection","type":"publication"},{"authors":["Yuanhang Su","Kai Fan","Nguyen Bach","C.-C. Jay Kuo","Fei Huang"],"categories":null,"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"b29f34392fcb2ca9d1f00ae3f857991e","permalink":"https://nguyenbh.github.io/publication/su-2019-cvpr/","publishdate":"2019-10-01T04:32:52.872805Z","relpermalink":"/publication/su-2019-cvpr/","section":"publication","summary":"Unsupervised neural machine translation (UNMT) has recently achieved remarkable results with only large monolingual corpora in each language. However, the uncertainty of associating target with source sentences makes UNMT theoretically an ill-posed problem. This work investigates the possibility of utilizing images for disambiguation to improve the performance of UNMT. Our assumption is intuitively based on the invariant property of image, i.e., the description of the same visual content by different languages should be approximately similar. We propose an unsupervised multi-modal machine translation (UMNMT) framework based on the language translation cycle consistency loss conditional on the image, targeting to learn the bidirectional multi-modal translation simultaneously. Through an alternate training between multi-modal and uni-modal, our inference model can translate with or without the image. On the widely used Multi30K dataset, the experimental results of our approach are significantly better than those of the text-only UNMT on the 2016 test dataset.","tags":null,"title":"Unsupervised Multi-Modal Neural Machine Translation","type":"publication"},{"authors":["Nguyen Bach","Hongjie Chen","Kai Fan","Cheung-Chi Leung","Bo Li","Chongjia Ni","Rong Tong","Pei Zhang","Boxing Chen","Bin Ma","Fei Huang"],"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"288af1f12439b748676cb3010cd1ed4b","permalink":"https://nguyenbh.github.io/publication/alibaba-2018-iwslt/","publishdate":"2019-10-01T04:59:39.215995Z","relpermalink":"/publication/alibaba-2018-iwslt/","section":"publication","summary":"This work describes the Enâ†’De Alibaba speech translation system developed for the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2018. In order to improve ASR performance, multiple ASR models including conventional and end-to-end models are built, then we apply model fusion in the final step. ASR pre and post- processing techniques such as speech segmentation, punctuation insertion, and sentence splitting are found to be very useful for MT. We also employed most techniques that have proven effective during the WMT 2018 evaluation, such as BPE, back translation, data selection, model ensembling and reranking. These ASR and MT techniques, combined, improve the speech translation quality significantly.","tags":null,"title":"Alibaba Speech TranslationSystems for IWSLT 2018","type":"publication"},{"authors":["Vaibhav Thukral","Chris Aholt","Christopher Maurice Mei","Bill Chau","Nguyen Bach","Lev Cherkashin","Jaeyoun Kim"],"categories":null,"content":"","date":1482480000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1482480000,"objectID":"2523ca2742497b20cd6542c31a144b66","permalink":"https://nguyenbh.github.io/publication/eye-tracking-uspto-2016/","publishdate":"2018-06-28T00:00:00-07:00","relpermalink":"/publication/eye-tracking-uspto-2016/","section":"publication","summary":"Disclosed are an apparatus and a method of low-latency, low-power eye tracking. In some embodiments, the eye tracking method operates a first sensor having a first level of power consumption that tracks positions of an eye of a user. In response to detection that the eye does not change position for a time period, the method stops operation of the first sensor and instead operates a second sensor that detects a change of position of the eye. The second sensor has a level of power consumption lower than the level of power consumption of the first sensor. Once the eye position changes, the second sensor resumes operation.","tags":null,"title":"Eye Tracking Using Video Information and Electrooculography Information","type":"publication"},{"authors":["Radu Soricut","Nguyen Bach","Ziyuan Wang"],"categories":null,"content":"","date":1338508800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1338508800,"objectID":"0179b8915b575e7c1a6bc89d1f360f7f","permalink":"https://nguyenbh.github.io/publication/soricut-bach-wang-2012-wmt/","publishdate":"2019-10-01T04:32:52.874982Z","relpermalink":"/publication/soricut-bach-wang-2012-wmt/","section":"publication","summary":"We present in this paper the system sub-missions of the SDL Language Weaver team in the WMT 2012 Quality Estimation shared-task. Our MT quality-prediction systems use machine learning techniques (M5P regression-tree and SVM-regression models) and a feature-selection algorithm that has been designed to directly optimize towards the official metrics used in this shared-task. The resulting submissions placed 1st (the M5P model) and 2nd (the SVM model), respectively, on both the Ranking task and the Scoring task, out of 11 participating teams.","tags":null,"title":"The SDL Language Weaver Systems in the WMT12 Quality Estimation Shared Task","type":"publication"},{"authors":["Nguyen Bach","Qin Gao","Stephan Vogel","Alex Waibel"],"categories":null,"content":"","date":1320105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1320105600,"objectID":"fb59082ed441d9f6e0ca2b9affae9088","permalink":"https://nguyenbh.github.io/publication/bach-et-al-2011-ijcnlp-2011/","publishdate":"2019-10-01T04:59:39.217754Z","relpermalink":"/publication/bach-et-al-2011-ijcnlp-2011/","section":"publication","summary":"We propose a statistical sentence simplification system with log-linear models. In contrast to state-of-the-art methods that drive sentence simplification process by hand-written linguistic rules, our method used a margin-based discriminative learning algorithm operates on a feature set. The feature set is defined on statistics of surface form as well as syntactic and dependency structures of the sentences. A stack decoding algorithm is used which allows us to efficiently generate and search simplification hypotheses. Experimental results show that the simplified text produced by the proposed system reduces 1.7 Flesch-Kincaid grade level when compared with the original text. We will show that a comparison of a state-ofthe-art rule-based system (Heilman and Smith, 2010) to the proposed system demonstrates an improvement of 0.2, 0.6, and 4.5 points in ROUGE-2, ROUGE-4, and AveF10, respectively.","tags":null,"title":"TriS: A Statistical Sentence Simplifier with Log-linear Models and Margin-based Discriminative Training","type":"publication"},{"authors":["Sanjika Hewavitharana","Nguyen Bach","Qin Gao","Vamshi Ambati","Stephan Vogel"],"categories":null,"content":"","date":1309478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1309478400,"objectID":"4c69db7600a47da0e2ed9243fb369cdd","permalink":"https://nguyenbh.github.io/publication/hewavitharana-et-al-2011-wmt/","publishdate":"2019-10-01T04:59:39.219705Z","relpermalink":"/publication/hewavitharana-et-al-2011-wmt/","section":"publication","summary":"This paper describes the statistical machine translation system submitted to the WMT11 Featured Translation Task, which involves translating Haitian Creole SMS messages into English. In our experiments we try to address the issue of noisy training data, as well as lack of parallel training data. Spelling normalization is applied to reduce out-of-vocabulary words in the corpus. Using Semantic Role Labeling rules we expand the available training corpus. We also investigate extracting parallel sentences from comparable corpora to enhance the available parallel data.","tags":null,"title":"CMU Haitian Creole-English Translation System for WMT 2011","type":"publication"},{"authors":["Nguyen Bach","Fei Huang","Yaser Al-Onaizan"],"categories":null,"content":"","date":1306911600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1306911600,"objectID":"bd30dcaf7ac2cc9b9e20c5f3192f3a2f","permalink":"https://nguyenbh.github.io/publication/bach-huang-alonaizan-2011-acl-hlt-2011/","publishdate":"2019-10-01T04:59:39.218884Z","relpermalink":"/publication/bach-huang-alonaizan-2011-acl-hlt-2011/","section":"publication","summary":"State-of-the-art statistical machine translation (MT) systems have made significant progress towards producing user-acceptable translation output. However, there is still no efficient way for MT systems to inform users which words are likely translated correctly and how confident it is about the whole sentence. We propose a novel framework to predict wordlevel and sentence-level MT errors with a large number of novel features. Experimental results show that the MT error prediction accuracy is increased from 69.1 to 72.2 in F-score. The Pearson correlation between the proposed confidence measure and the human-targeted translation edit rate (HTER) is 0.6. Improvements between 0.4 and 0.9 TER reduction are obtained with the n-best list reranking task using the proposed confidence measure. Also, we present a visualization prototype of MT errors at the word and sentence levels with the objective to improve post-editor productivity.","tags":null,"title":"Goodness = A Method for Measuring Machine Translation Confidence","type":"publication"}]