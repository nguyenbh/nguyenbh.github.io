[{"authors":["admin"],"categories":null,"content":"I am currently a principal engineer at Microsoft GenAI. My main focus is to bring GenAI to practically serve Microsoft and its custmers on realistic scenarios. In the last few years, I\n help to drive the creation and release of the Phi model series including Phi-4-multimodal, Phi-4-mini (February, 2025), Phi-3.5, Phi-3 to both open source community and Azure AI. drove AI strategies at scale and bring clarity to the leadership team at the Microsoft Office of the CTO, particularly on large model training roadmap and product scenarios.  My professional career is a mix of industrial research labs and startups. I spend a few years at the Machine Intelligence Technology Lab, DAMO Academy, Alibaba. My main focus is to break the language barriers across the Alibaba ecosystem by researching and developing AI solutions for eCommerce scenarios. I was an early machine learning engineer at Textio, a start-up of augmented writing, where I was responsible for training and deploying prediction models. I worked for Microsoft on machine learning models in wearable devices such as the HoloLens project. I was a machine translations researcher at SDL. I am actively coaching and consultanting early-stage startups and young engineers in Vietnam.\nSpecialties: GenAI, AI strategies, LLM, multimodal, AI product deployments.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://nguyenbh.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am currently a principal engineer at Microsoft GenAI. My main focus is to bring GenAI to practically serve Microsoft and its custmers on realistic scenarios. In the last few years, I\n help to drive the creation and release of the Phi model series including Phi-4-multimodal, Phi-4-mini (February, 2025), Phi-3.5, Phi-3 to both open source community and Azure AI. drove AI strategies at scale and bring clarity to the leadership team at the Microsoft Office of the CTO, particularly on large model training roadmap and product scenarios.","tags":null,"title":"","type":"authors"},{"authors":["Yujia Xie","Luowei Zhou","Xiyang Dai","Lu Yuan","Nguyen Bach","Ce Liu","Michael Zeng"],"categories":null,"content":"","date":1663113600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663113600,"objectID":"8a38bd465b8b4d62c2563fe748b9f15e","permalink":"https://nguyenbh.github.io/publication/xie-et-al-2022-neurips/","publishdate":"2022-09-14T00:00:00Z","relpermalink":"/publication/xie-et-al-2022-neurips/","section":"publication","summary":"People say, *A picture is worth a thousand words*. Then how can we get the rich information out of the image? We argue that by using visual clues to bridge large pretrained vision foundation models and language models, we can do so without any extra cross-modal training. Thanks to the strong zero-shot capability of foundation models, we start by constructing a rich semantic representation of the image (e.g., image tags, object attributes / locations, captions) as a structured textual prompt, called visual clues, using a vision foundation model. Based on visual clues, we use large language model to produce a series of comprehensive descriptions for the visual content, which is then verified by the vision model again to select the candidate that aligns best with the image. We evaluate the quality of generated descriptions by quantitative and qualitative measurement. The results demonstrate the effectiveness of such a structured semantic representation.","tags":null,"title":"Visual Clues: Bridging Vision and Language Foundations for Image Paragraph Captioning","type":"publication"},{"authors":["Xinyu Wang","Min Gui","Yong Jiang","Zixia Jia","Nguyen Bach","Tao Wang","Zhongqiang Huang","Fei Huang","Kewei Tu"],"categories":null,"content":"","date":1657497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657497600,"objectID":"5d31c537fe67a941fe153df226c930e6","permalink":"https://nguyenbh.github.io/publication/wang-et-al-2022-naacl/","publishdate":"2022-07-11T00:00:00Z","relpermalink":"/publication/wang-et-al-2022-naacl/","section":"publication","summary":"Recently, Multi-modal Named Entity Recognition (MNER) has attracted a lot of attention. Most of the work utilizes image information through region-level visual representations obtained from a pretrained object detector and relies on an attention mechanism to model the interactions between image and text representations. However, it is difficult to model such interactions as image and text representations are trained separately on the data of their respective modality and are not aligned in the same space. As text representations take the most important role in MNER, in this paper, we propose Image-text Alignments (ITA) to align image features into the textual space, so that the attention mechanism in transformer-based pretrained textual embeddings can be better utilized. ITA first aligns the image into regional object tags, image-level captions and optical characters as visual contexts, concatenates them with the input texts as a new cross-modal input, and then feeds it into a pretrained textual embedding model. This makes it easier for the attention module of a pretrained textual embedding model to model the interaction between the two modalities since they are both represented in the textual space. ITA further aligns the output distributions predicted from the cross-modal input and textual input views so that the MNER model can be more practical in dealing with text-only inputs and robust to noises from images. In our experiments, we show that ITA models can achieve state-of-the-art accuracy on multi-modal Named Entity Recognition datasets, even without image information.","tags":null,"title":"ITA: Image-Text Alignments for Multi-Modal Named Entity Recognition","type":"publication"},{"authors":["Yujia Xie","Lu Yuan","Nguyen Bach"],"categories":null,"content":"","date":1656486000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656486000,"objectID":"6d7c8372847d4039bb5b93bb0b29c5bc","permalink":"https://nguyenbh.github.io/publication/image-paragraph-generator-2022/","publishdate":"2023-12-07T00:00:00-08:00","relpermalink":"/publication/image-paragraph-generator-2022/","section":"publication","summary":"Example solutions for image paragraph captioning use a first vision language model to generate visual information (comprising text) for an image. The visual information may include tags, an initial image caption, and information on objects within the image (e.g., further tags and captions, and object attributes and locations within the image). In some examples, the visual information further includes visual clues. A generative language model generates a plurality of image story caption candidates (e.g., descriptive paragraphs) from the visual information. A second vision language model evaluates the plurality of image story caption candidates and selects a caption as the final output caption.","tags":null,"title":"Image paragraph generator","type":"publication"},{"authors":["Yujia Xie","Lu Yuan","Nguyen Bach"],"categories":null,"content":"","date":1656486000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656486000,"objectID":"5cab286ff7ab9bdcc0a0687ab9afe39b","permalink":"https://nguyenbh.github.io/publication/interact-llm-with-external-knowledge/","publishdate":"2023-12-07T00:00:00-08:00","relpermalink":"/publication/interact-llm-with-external-knowledge/","section":"publication","summary":"Example solutions for image paragraph captioning use a first vision language model to generate visual information (comprising text) for an image. The visual information may include tags, an initial image caption, and information on objects within the image (e.g., further tags and captions, and object attributes and locations within the image). In some examples, the visual information further includes visual clues. A generative language model generates a plurality of image story caption candidates (e.g., descriptive paragraphs) from the visual information. A second vision language model evaluates the plurality of image story caption candidates and selects a caption as the final output caption.","tags":null,"title":"Image paragraph generator","type":"publication"},{"authors":["Gopi Kumar","Jiayuan Huang","Nguyen Bach","Luis Vargas"],"categories":null,"content":"","date":1644278400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644278400,"objectID":"487a9d656da5f44e1f4f5a0f07c8c1cd","permalink":"https://nguyenbh.github.io/publication/microsoft-blog-022022/","publishdate":"2022-02-08T00:00:00Z","relpermalink":"/publication/microsoft-blog-022022/","section":"publication","summary":"We believe that every organization in the world should benefit from the power of these models, which is why Microsoft’s AI at Scale initiative is making these large models – and the systems and infrastructure to enable training and utilization – available as a platform. Fueling this initiative is Microsoft’s cutting-edge research on AI, guided by real-world applications and scenarios. Microsoft Research has been at the forefront of AI advancements with breakthroughs across natural-language processing, computer vision, speech recognition and more. We decided to develop platforms, tools and a supercomputing infrastructure that would allow any developer to build and scale their own AI innovation. At the Microsoft Build 2020 developer conference, we announced the Microsoft AI at Scale initiative, dedicated to giving all organizations access to these powerful AI models.Since then, continued progress in both fundamental and applied AI research has translated into ever-more transformative products, services and operations – which Microsoft is committed to making accessible to all. This blog post explores the innovations behind the Microsoft AI at Scale initiative.","tags":null,"title":"The innovation behind AI at Scale","type":"publication"},{"authors":["Xinyin Ma","Yong Jiang","Nguyen Bach","Tao Wang","Zhongqiang Huang","Fei Huang","Weiming Lu"],"categories":null,"content":"","date":1635811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635811200,"objectID":"08a77b9abd6d8a243367eddb88b64846","permalink":"https://nguyenbh.github.io/publication/ma-et-al-2021-emnlp/","publishdate":"2021-11-02T00:00:00Z","relpermalink":"/publication/ma-et-al-2021-emnlp/","section":"publication","summary":"Entity retrieval, which aims at disambiguating mentions to canonical entities from massive KBs, is essential for many tasks in natural language processing. Recent progress in entity retrieval shows that the dual-encoder structure is a powerful and efficient framework to nominate candidates if entities are only identified by descriptions. However, they ignore the property that meanings of entity mentions diverge in different contexts and are related to various portions of descriptions, which are treated equally in previous works. In this work, we propose Multi-View Entity Representations (MuVER), a novel approach for entity retrieval that constructs multi-view representations for entity descriptions and approximates the optimal view for mentions via a heuristic searching method. Our method achieves the state-of-the-art performance on ZESHEL and improves the quality of candidates on three standard Entity Linking datasets.","tags":null,"title":"MuVER: Improving First-Stage Entity Retrieval with Multi-View Entity Representations","type":"publication"},{"authors":["Xinyu Wang","Yong Jiang","Nguyen Bach","Tao Wang","Zhongqiang Huang","Fei Huang","Kewei Tu"],"categories":null,"content":"","date":1627862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627862400,"objectID":"355ae71008bba797b481dfd739a2e478","permalink":"https://nguyenbh.github.io/publication/wang-et-al-2021-acl-ace/","publishdate":"2021-08-02T00:00:00Z","relpermalink":"/publication/wang-et-al-2021-acl-ace/","section":"publication","summary":"Pretrained contextualized embeddings are powerful word representations for structured prediction tasks. Recent work found that better word representations can be obtained by concatenating different types of embeddings. However, the selection of embeddings to form the best concatenated representation usually varies depending on the task and the collection of candidate embeddings, and the ever-increasing number of embedding types makes it a more difficult problem. In this paper, we propose Automated Concatenation of Embeddings (ACE) to automate the process of finding better concatenations of embeddings for structured prediction tasks, based on a formulation inspired by recent progress on neural architecture search. Specifically, a controller alternately samples a concatenation of embeddings, according to its current belief of the effectiveness of individual embedding types in consideration for a task, and updates the belief based on a reward. We follow strategies in reinforcement learning to optimize the parameters of the controller and compute the reward based on the accuracy of a task model, which is fed with the sampled concatenation as input and trained on a task dataset. Empirical results on 6 tasks and 21 datasets show that our approach outperforms strong baselines and achieves state-of-the-art performance with fine-tuned embeddings in all the evaluations.","tags":null,"title":"Automated Concatenation of Embeddings for Structured Prediction","type":"publication"},{"authors":["Xinyu Wang","Yong Jiang","Nguyen Bach","Tao Wang","Zhongqiang Huang","Fei Huang","Kewei Tu"],"categories":null,"content":"","date":1627862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627862400,"objectID":"bf379c2ce714dbc005cd227172beb7b2","permalink":"https://nguyenbh.github.io/publication/wang-et-al-2021-acl-ner/","publishdate":"2021-08-02T00:00:00Z","relpermalink":"/publication/wang-et-al-2021-acl-ner/","section":"publication","summary":"Recent advances in Named Entity Recognition (NER) show that document-level contexts can significantly improve model performance. In many application scenarios, however, such contexts are not available. In this paper, we propose to find external contexts of a sentence by retrieving and selecting a set of semantically relevant texts through a search engine, with the original sentence as the query. We find empirically that the contextual representations computed on the retrieval-based input view, constructed through the concatenation of a sentence and its external contexts, can achieve significantly improved performance compared to the original input view based only on the sentence. Furthermore, we can improve the model performance of both input views by Cooperative Learning, a training method that encourages the two input views to produce similar contextual representations or output label distributions. Experiments show that our approach can achieve new state-of-the-art performance on 8 NER data sets across 5 domains.","tags":null,"title":"Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning","type":"publication"},{"authors":["Zechuan Hu","Yong Jiang","Nguyen Bach","Tao Wang","Zhongqiang Huang","Fei Huang","Kewei Tu"],"categories":null,"content":"","date":1627862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627862400,"objectID":"a1cc56603efee1204fb2f65905e6ed83","permalink":"https://nguyenbh.github.io/publication/hu-et-al-2021-acl-multiview/","publishdate":"2021-08-02T00:00:00Z","relpermalink":"/publication/hu-et-al-2021-acl-multiview/","section":"publication","summary":"In structured prediction problems, cross-lingual transfer learning is an efficient way to train quality models for low-resource languages, and further improvement can be obtained by learning from multiple source languages. However, not all source models are created equal and some may hurt performance on the target language. Previous work has explored the similarity between source and target sentences as an approximate measure of strength for different source models. In this paper, we propose a multi-view framework, by leveraging a small number of labeled target sentences, to effectively combine multiple source models into an aggregated source view at different granularity levels (language, sentence, or sub-structure), and transfer it to a target view based on a task-specific model. By encouraging the two views to interact with each other, our framework can dynamically adjust the confidence level of each source model and improve the performance of both views during training. Experiments for three structured prediction tasks on sixteen data sets show that our framework achieves significant improvement over all existing approaches, including these with access to additional source language data.","tags":null,"title":"Multi-View Cross-Lingual Structured Prediction with Minimum Supervision","type":"publication"},{"authors":["Zechuan Hu","Yong Jiang","Nguyen Bach","Tao Wang","Zhongqiang Huang","Fei Huang","Kewei Tu"],"categories":null,"content":"","date":1627862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627862400,"objectID":"5304ba7e20ef61ec983ba68ffbf1737d","permalink":"https://nguyenbh.github.io/publication/hu-et-al-2021-acl-risk/","publishdate":"2021-08-02T00:00:00Z","relpermalink":"/publication/hu-et-al-2021-acl-risk/","section":"publication","summary":"Zero-shot sequence labeling aims to build a sequence labeler without human-annotated datasets. One straightforward approach is utilizing existing systems (source models) to generate pseudo-labeled datasets and train a target sequence labeler accordingly. However, due to the gap between the source and the target languages/domains, this approach may fail to recover the true labels. In this paper, we propose a novel unified framework for zero-shot sequence labeling with minimum risk training and design a new decomposable risk function that models the relations between the predicted labels from the source models and the true labels. By making the risk function trainable, we draw a connection between minimum risk training and latent variable model learning. We propose a unified learning algorithm based on the expectation maximization (EM) algorithm. We extensively evaluate our proposed approaches on cross-lingual/domain sequence labeling tasks over twenty-one datasets. The results show that our approaches outperform state-of-the-art baseline systems.","tags":null,"title":"Risk Minimization for Zero-shot Sequence Labeling","type":"publication"},{"authors":["Xinyu Wang","Yong Jiang","Zhaohui Yan","Zixia Jia","Nguyen Bach","Tao Wang","Zhongqiang Huang","Fei Huang","Kewei Tu"],"categories":null,"content":"","date":1627862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627862400,"objectID":"87874fca50bfdf6b90455117a3ea4443","permalink":"https://nguyenbh.github.io/publication/wang-et-al-2021-acl-structurekd/","publishdate":"2021-08-02T00:00:00Z","relpermalink":"/publication/wang-et-al-2021-acl-structurekd/","section":"publication","summary":"Knowledge distillation is a critical technique to transfer knowledge between models, typically from a large model (the teacher) to a more fine-grained one (the student). The objective function of knowledge distillation is typically the cross-entropy between the teacher and the student{'}s output distributions. However, for structured prediction problems, the output space is exponential in size; therefore, the cross-entropy objective becomes intractable to compute and optimize directly. In this paper, we derive a factorized form of the knowledge distillation objective for structured prediction, which is tractable for many typical choices of the teacher and student models. In particular, we show the tractability and empirical effectiveness of structural knowledge distillation between sequence labeling and dependency parsing models under four different scenarios: 1) the teacher and student share the same factorization form of the output structure scoring function; 2) the student factorization produces more fine-grained substructures than the teacher factorization; 3) the teacher factorization produces more fine-grained substructures than the student factorization; 4) the factorization forms from the teacher and the student are incompatible.","tags":null,"title":"Structural Knowledge Distillation: Tractably Distilling Information for Structured Predictor","type":"publication"},{"authors":["Xinyu Wang","Yong Jiang","Nguyen Bach","Tao Wang","Zhongqiang Huang","Fei Huang","Kewei Tu"],"categories":null,"content":"","date":1605052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605052800,"objectID":"20eee3be5770c1244b8d2350cdf0a145","permalink":"https://nguyenbh.github.io/publication/wang-et-al-2020-emnlp/","publishdate":"2020-11-11T00:00:00Z","relpermalink":"/publication/wang-et-al-2020-emnlp/","section":"publication","summary":"The linear-chain Conditional Random Field (CRF) model is one of the most widely-used neural sequence labeling approaches. Exact probabilistic inference algorithms such as the forward-backward and Viterbi algorithms are typically applied in training and prediction stages of the CRF model. However, these algorithms require sequential computation that makes parallelization impossible. In this paper, we propose to employ a parallelizable approximate variational inference algorithm for the CRF model. Based on this algorithm, we design an approximate inference network that can be connected with the encoder of the neural CRF model to form an end-to-end network, which is amenable to parallelization for faster training and prediction. The empirical results show that our proposed approaches achieve a 12.7-fold improvement in decoding speed with long sentences and a competitive accuracy compared with the traditional CRF approach.","tags":null,"title":"AIN: Fast and Accurate Sequence Labeling with Approximate Inference Network","type":"publication"},{"authors":["Zechuan Hu","Yong Jiang","Nguyen Bach","Tao Wang","Zhongqiang Huang","Fei Huang","Kewei Tu"],"categories":null,"content":"","date":1605052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605052800,"objectID":"bbed55d377c99f0bf1255b7ff9acafe3","permalink":"https://nguyenbh.github.io/publication/hu-et-al-2020-emnlp-findings/","publishdate":"2020-11-11T00:00:00Z","relpermalink":"/publication/hu-et-al-2020-emnlp-findings/","section":"publication","summary":"The neural linear-chain CRF model is one of the most widely-used approach to sequence labeling. In this paper, we investigate a series of increasingly expressive potential functions for neural CRF models, which not only integrate the emission and transition functions, but also explicitly take the representations of the contextual words as input. Our extensive experiments show that the decomposed quadrilinear potential function based on the vector representations of two neighboring labels and two neighboring words consistently achieves the best performance.","tags":null,"title":"An Investigation of Potential Function Designs for Neural CRF","type":"publication"},{"authors":["Xinyu Wang","Yong Jiang","Nguyen Bach","Tao Wang","Zhongqiang Huang","Fei Huang","Kewei Tu"],"categories":null,"content":"","date":1605052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605052800,"objectID":"ac76ac1569ca1c26ff7da75fcc23da1a","permalink":"https://nguyenbh.github.io/publication/wang-et-al-2020-emnlp-findings/","publishdate":"2020-11-11T00:00:00Z","relpermalink":"/publication/wang-et-al-2020-emnlp-findings/","section":"publication","summary":"Recent work proposes a family of contextual embeddings that significantly improves the accuracy of sequence labelers over non-contextual embeddings. However, there is no definite conclusion on whether we can build better sequence labelers by combining different kinds of embeddings in various settings. In this paper, we conduct extensive experiments on 3 tasks over 18 datasets and 8 languages to study the accuracy of sequence labeling with various embedding concatenations and make three observations: (1) concatenating more embedding variants leads to better accuracy in rich-resource and cross-domain settings and some conditions of low-resource settings; (2) concatenating contextual sub-word embeddings with contextual character embeddings hurts the accuracy in extremely low-resource settings; (3) based on the conclusion of (1), concatenating additional similar contextual embeddings cannot lead to further improvements. We hope these conclusions can help people build stronger sequence labelers in various settings.","tags":null,"title":"More Embeddings, Better Sequence Labelers?","type":"publication"},{"authors":["Xinyu Wang","Yong Jiang","Nguyen Bach","Tao Wang","Fei Huang","Kewei Tu"],"categories":null,"content":"","date":1592438400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592438400,"objectID":"bff196ebf2f7b5dadc3e10371bc508cc","permalink":"https://nguyenbh.github.io/publication/wang-et-al-2020-acl/","publishdate":"2020-06-18T00:00:00Z","relpermalink":"/publication/wang-et-al-2020-acl/","section":"publication","summary":"Multilingual sequence labeling is a task of predicting label sequences using a single unified model for multiple languages. Compared with relying on multiple monolingual models, using a multilingual model has the benefit of a smaller model size, easier in online serving, and generalizability to low-resource languages. However, current multilingual models still underperform individual monolingual models significantly due to model capacity limitations. In this paper, we propose to reduce the gap between monolingual models and the unified multilingual model by distilling the structural knowledge of several monolingual models (teachers) to the unified multilingual model (student). We propose two novel KD methods based on structure-level information: (1) approximately minimizes the distance between the student’s and the teachers’ structure-level probability distributions, (2) aggregates the structure-level knowledge to local distributions and minimizes the distance between two local probability distributions. Our experiments on 4 multilingual tasks with 25 datasets show that our approaches outperform several strong baselines and have stronger zero-shot generalizability than both the baseline model and teacher models.","tags":null,"title":"Structure-Level Knowledge Distillation For Multilingual Sequence Labeling","type":"publication"},{"authors":["Ebrahim Ansari","amittai axelrod","Nguyen Bach","Ondřej Bojar","Roldano Cattoni","Fahim Dalvi","Nadir Durrani","Marcello Federico","Christian Federmann","Jiatao Gu","Fei Huang","Kevin Knight","Xutai Ma","Ajay Nagesh","Matteo Negri","Jan Niehues","Juan Pino","Elizabeth Salesky","Xing Shi","Sebastian Stüker","Marco Turchi","Alexander Waibel","Changhan Wang"],"categories":null,"content":"","date":1592352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592352000,"objectID":"774b7fa61b0b76e85cf91b580370ee85","permalink":"https://nguyenbh.github.io/publication/iwslt-2020/","publishdate":"2020-06-17T00:00:00Z","relpermalink":"/publication/iwslt-2020/","section":"publication","summary":"The evaluation campaign of the International Conference on Spoken Language Translation (IWSLT 2020) featured this year six challenge tracks: (i) Simultaneous speech translation, (ii) Video speech translation, (iii) Offline speech translation, (iv) Conversational speech translation, (v) Open domain translation, and (vi) Non-native speech translation. A total of teams participated in at least one of the tracks. This paper introduces each track’s goal, data and evaluation metrics, and reports the results of the received submissions.","tags":null,"title":"FINDINGS OF THE IWSLT 2020 EVALUATION CAMPAIGN","type":"publication"},{"authors":["Nguyen Bach","Fei Huang"],"categories":null,"content":"","date":1568851200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568851200,"objectID":"7651b12fa2f73a9d7817de6d6852bcb8","permalink":"https://nguyenbh.github.io/publication/noisy-bilstm-based-models-for-disfluency-detection/","publishdate":"2019-09-19T00:00:00Z","relpermalink":"/publication/noisy-bilstm-based-models-for-disfluency-detection/","section":"publication","summary":"This paper describes BiLSTM-based models to disfluency detection in speech transcripts using residual BiLSTM blocks, self-attention, and noisy training approach. Our best model not only surpasses BERT in 4 non-Switchboard test sets, but also is 20 times smaller than the BERT-based model. Thus, we demonstrate that strong performance can be achieved without extensively use of very large training data. In addition, we show that it is possible to be robust across data sets with noisy training approach in which we found insertion is the most useful noise for augmenting training data.","tags":null,"title":"Noisy BiLSTM-Based Models for Disfluency Detection","type":"publication"},{"authors":["Yuanhang Su","Kai Fan","Nguyen Bach","C.-C. Jay Kuo","Fei Huang"],"categories":null,"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"b29f34392fcb2ca9d1f00ae3f857991e","permalink":"https://nguyenbh.github.io/publication/su-2019-cvpr/","publishdate":"2019-10-01T04:32:52.872805Z","relpermalink":"/publication/su-2019-cvpr/","section":"publication","summary":"Unsupervised neural machine translation (UNMT) has recently achieved remarkable results with only large monolingual corpora in each language. However, the uncertainty of associating target with source sentences makes UNMT theoretically an ill-posed problem. This work investigates the possibility of utilizing images for disambiguation to improve the performance of UNMT. Our assumption is intuitively based on the invariant property of image, i.e., the description of the same visual content by different languages should be approximately similar. We propose an unsupervised multi-modal machine translation (UMNMT) framework based on the language translation cycle consistency loss conditional on the image, targeting to learn the bidirectional multi-modal translation simultaneously. Through an alternate training between multi-modal and uni-modal, our inference model can translate with or without the image. On the widely used Multi30K dataset, the experimental results of our approach are significantly better than those of the text-only UNMT on the 2016 test dataset.","tags":null,"title":"Unsupervised Multi-Modal Neural Machine Translation","type":"publication"},{"authors":["Nguyen Bach","Hongjie Chen","Kai Fan","Cheung-Chi Leung","Bo Li","Chongjia Ni","Rong Tong","Pei Zhang","Boxing Chen","Bin Ma","Fei Huang"],"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"288af1f12439b748676cb3010cd1ed4b","permalink":"https://nguyenbh.github.io/publication/alibaba-2018-iwslt/","publishdate":"2019-10-01T04:59:39.215995Z","relpermalink":"/publication/alibaba-2018-iwslt/","section":"publication","summary":"This work describes the En→De Alibaba speech translation system developed for the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2018. In order to improve ASR performance, multiple ASR models including conventional and end-to-end models are built, then we apply model fusion in the final step. ASR pre and post- processing techniques such as speech segmentation, punctuation insertion, and sentence splitting are found to be very useful for MT. We also employed most techniques that have proven effective during the WMT 2018 evaluation, such as BPE, back translation, data selection, model ensembling and reranking. These ASR and MT techniques, combined, improve the speech translation quality significantly.","tags":null,"title":"Alibaba Speech Translation Systems for IWSLT 2018","type":"publication"},{"authors":["Vaibhav Thukral","Chris Aholt","Christopher Maurice Mei","Bill Chau","Nguyen Bach","Lev Cherkashin","Jaeyoun Kim"],"categories":null,"content":"","date":1482480000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1482480000,"objectID":"2523ca2742497b20cd6542c31a144b66","permalink":"https://nguyenbh.github.io/publication/eye-tracking-uspto-2016/","publishdate":"2018-06-28T00:00:00-07:00","relpermalink":"/publication/eye-tracking-uspto-2016/","section":"publication","summary":"Disclosed are an apparatus and a method of low-latency, low-power eye tracking. In some embodiments, the eye tracking method operates a first sensor having a first level of power consumption that tracks positions of an eye of a user. In response to detection that the eye does not change position for a time period, the method stops operation of the first sensor and instead operates a second sensor that detects a change of position of the eye. The second sensor has a level of power consumption lower than the level of power consumption of the first sensor. Once the eye position changes, the second sensor resumes operation.","tags":null,"title":"Eye Tracking Using Video Information and Electrooculography Information","type":"publication"},{"authors":["Radu Soricut","Nguyen Bach","Ziyuan Wang"],"categories":null,"content":"","date":1338508800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1338508800,"objectID":"0179b8915b575e7c1a6bc89d1f360f7f","permalink":"https://nguyenbh.github.io/publication/soricut-bach-wang-2012-wmt/","publishdate":"2019-10-01T04:32:52.874982Z","relpermalink":"/publication/soricut-bach-wang-2012-wmt/","section":"publication","summary":"We present in this paper the system sub-missions of the SDL Language Weaver team in the WMT 2012 Quality Estimation shared-task. Our MT quality-prediction systems use machine learning techniques (M5P regression-tree and SVM-regression models) and a feature-selection algorithm that has been designed to directly optimize towards the official metrics used in this shared-task. The resulting submissions placed 1st (the M5P model) and 2nd (the SVM model), respectively, on both the Ranking task and the Scoring task, out of 11 participating teams.","tags":null,"title":"The SDL Language Weaver Systems in the WMT12 Quality Estimation Shared Task","type":"publication"},{"authors":["Nguyen Bach","Qin Gao","Stephan Vogel","Alex Waibel"],"categories":null,"content":"","date":1320105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1320105600,"objectID":"fb59082ed441d9f6e0ca2b9affae9088","permalink":"https://nguyenbh.github.io/publication/bach-et-al-2011-ijcnlp-2011/","publishdate":"2019-10-01T04:59:39.217754Z","relpermalink":"/publication/bach-et-al-2011-ijcnlp-2011/","section":"publication","summary":"We propose a statistical sentence simplification system with log-linear models. In contrast to state-of-the-art methods that drive sentence simplification process by hand-written linguistic rules, our method used a margin-based discriminative learning algorithm operates on a feature set. The feature set is defined on statistics of surface form as well as syntactic and dependency structures of the sentences. A stack decoding algorithm is used which allows us to efficiently generate and search simplification hypotheses. Experimental results show that the simplified text produced by the proposed system reduces 1.7 Flesch-Kincaid grade level when compared with the original text. We will show that a comparison of a state-ofthe-art rule-based system (Heilman and Smith, 2010) to the proposed system demonstrates an improvement of 0.2, 0.6, and 4.5 points in ROUGE-2, ROUGE-4, and AveF10, respectively.","tags":null,"title":"TriS: A Statistical Sentence Simplifier with Log-linear Models and Margin-based Discriminative Training","type":"publication"},{"authors":["Sanjika Hewavitharana","Nguyen Bach","Qin Gao","Vamshi Ambati","Stephan Vogel"],"categories":null,"content":"","date":1309478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1309478400,"objectID":"4c69db7600a47da0e2ed9243fb369cdd","permalink":"https://nguyenbh.github.io/publication/hewavitharana-et-al-2011-wmt/","publishdate":"2019-10-01T04:59:39.219705Z","relpermalink":"/publication/hewavitharana-et-al-2011-wmt/","section":"publication","summary":"This paper describes the statistical machine translation system submitted to the WMT11 Featured Translation Task, which involves translating Haitian Creole SMS messages into English. In our experiments we try to address the issue of noisy training data, as well as lack of parallel training data. Spelling normalization is applied to reduce out-of-vocabulary words in the corpus. Using Semantic Role Labeling rules we expand the available training corpus. We also investigate extracting parallel sentences from comparable corpora to enhance the available parallel data.","tags":null,"title":"CMU Haitian Creole-English Translation System for WMT 2011","type":"publication"},{"authors":["Nguyen Bach","Fei Huang","Yaser Al-Onaizan"],"categories":null,"content":"","date":1306911600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1306911600,"objectID":"bd30dcaf7ac2cc9b9e20c5f3192f3a2f","permalink":"https://nguyenbh.github.io/publication/bach-huang-alonaizan-2011-acl-hlt-2011/","publishdate":"2019-10-01T04:59:39.218884Z","relpermalink":"/publication/bach-huang-alonaizan-2011-acl-hlt-2011/","section":"publication","summary":"State-of-the-art statistical machine translation (MT) systems have made significant progress towards producing user-acceptable translation output. However, there is still no efficient way for MT systems to inform users which words are likely translated correctly and how confident it is about the whole sentence. We propose a novel framework to predict wordlevel and sentence-level MT errors with a large number of novel features. Experimental results show that the MT error prediction accuracy is increased from 69.1 to 72.2 in F-score. The Pearson correlation between the proposed confidence measure and the human-targeted translation edit rate (HTER) is 0.6. Improvements between 0.4 and 0.9 TER reduction are obtained with the n-best list reranking task using the proposed confidence measure. Also, we present a visualization prototype of MT errors at the word and sentence levels with the objective to improve post-editor productivity.","tags":null,"title":"Goodness: A Method for Measuring Machine Translation Confidence","type":"publication"},{"authors":["Qin Gao","Nguyen Bach","Stephan Vogel"],"categories":null,"content":"","date":1277967600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1277967600,"objectID":"1cb2c1e9e2b0c67965693caa504f073f","permalink":"https://nguyenbh.github.io/publication/gao-bach-vogel-2010-wmt/","publishdate":"2019-10-02T03:41:53.24183Z","relpermalink":"/publication/gao-bach-vogel-2010-wmt/","section":"publication","summary":"We present a word alignment framework that can incorporate partial manual alignments. The core of the approach is a novel semi-supervised algorithm extending the widely used IBM Models with a constrained EM algorithm. The partial manual alignments can be obtained by human labelling or automatically by high-precision-low-recall heuristics. We demonstrate the usages of both methods by selecting alignment links from manually aligned corpus and apply links generated from bilingual dictionary on unlabelled data. For the first method, we conduct controlled experiments on Chinese-English and Arabic-English translation tasks to compare the quality of word alignment, and to measure effects of two different methods in selecting alignment links from manually aligned corpus. For the second method, we experimented with moderate-scale Chinese-English translation task. The experiment results show an average improvement of 0.33 BLEU point across 8 test sets.","tags":null,"title":"A Semi-Supervised Word Alignment Algorithm with Partial Manual Alignments","type":"publication"},{"authors":["Nguyen Bach","Qin Gao","Stephan Vogel"],"categories":null,"content":"","date":1249110000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1249110000,"objectID":"a7d1780bed1d440a5152b3cf97e3b06b","permalink":"https://nguyenbh.github.io/publication/bach-gao-vogel-2009-mt-summit/","publishdate":"2019-10-02T04:36:18.671245Z","relpermalink":"/publication/bach-gao-vogel-2009-mt-summit/","section":"publication","summary":"We propose a novel source-side dependency tree reordering model for statistical machine translation, in which subtree movements and constraints are represented as reordering events associated with the widely used lexicalized reordering models. This model allows us to not only efficiently capture the statistical distribution of the subtree-to-subtree transitions in training data, but also utilize it directly at the decoding time to guide the search process. Using subtree movements and constraints as features in a log-linear model, we are able to help the reordering models make better selections. It also allows the subtle importance of monolingual syntactic movements to be learned alongside other reordering features. We show improvements in translation quality in English-Spanish and English-Iraqi translation tasks.","tags":null,"title":"Source-side Dependency Tree Reordering Models with Subtree Movements and Constraints","type":"publication"},{"authors":["Ying Zhang","Nguyen Bach"],"categories":null,"content":"","date":1249110000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1249110000,"objectID":"c5b9ef74fc44529dfbf02319b20b45e3","permalink":"https://nguyenbh.github.io/publication/zhang-bach-2009-mt-summit/","publishdate":"2019-10-02T04:36:18.672911Z","relpermalink":"/publication/zhang-bach-2009-mt-summit/","section":"publication","summary":"In this paper, we describe our ongoing research project of Virtual Babel, a context-aware machine translation system for Second Life, one of the most popular virtual worlds. We augment the Second Life viewer to intercept the incoming/outgoing chat messages and reroute the message to a statistical machine translation server. The returned translations are appended to the original text message to help users to understand the foreign language. Virtual Babel provides a platform to study cross-lingual conversations facilitated by machine translation in virtual worlds and we observe interesting phenomena that are not present in document translations. Virtual Babel is aware of the non-verbal context of the conversation. Language model and translation models are trained from collected conversations and are used to generate translations according to observed non-verbal context of the conversation.","tags":null,"title":"Virtual Babel: Towards Context-Aware Machine Translation in Virtual Worlds","type":"publication"},{"authors":["Nguyen Bach","Stephan Vogel","Colin Cherry"],"categories":null,"content":"","date":1243839600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1243839600,"objectID":"150abecd4a56a72a6b06d8a615a72443","permalink":"https://nguyenbh.github.io/publication/bach-vogel-cherry-2009-naaclhlt-09-short/","publishdate":"2019-10-02T04:36:18.674236Z","relpermalink":"/publication/bach-vogel-cherry-2009-naaclhlt-09-short/","section":"publication","summary":"Cohesive constraints allow the phrase-based decoder to employ arbitrary, non-syntactic phrases, and encourage it to translate those phrases in an order that respects the source dependency tree structure. We present extensions of the cohesive constraints, such as exhaustive interruption count and rich interruption check. Furthermore, we present analyses related to the impact of cohesive constraints across language pairs with different reordering models and dependency parsers. Our experiments show that the cohesion-enhanced decoder performs statistically significant better than the standard phrasebased decoder on English-Spanish. Improvements between 0.4 and 1.8 BLEU point are also obtained on English-Iraqi, Arabic-English and Chinese-English systems.","tags":null,"title":"Cohesive Constraints in A Beam Search Phrase-based Decoder","type":"publication"},{"authors":["Nguyen Bach","Roger Hsiao","Matthias Eck","Paisarn Charoenpornsawat","Stephan Vogel","Tanja Schultz","Ian Lane","Alex Waibel","Alan Black"],"categories":null,"content":"","date":1243839600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1243839600,"objectID":"8e6074f1088023d1fe49e2a55c752ab6","permalink":"https://nguyenbh.github.io/publication/bach-et-al-2009-naaclhlt-09-short/","publishdate":"2019-10-02T04:36:18.675671Z","relpermalink":"/publication/bach-et-al-2009-naaclhlt-09-short/","section":"publication","summary":"In building practical two-way speech-to-speech translation systems the end user will always wish to use the system in an environment different from the original training data. As with all speech systems, it is important to allow the system to adapt to the actual usage situations. This paper investigates how a speech-to-speech translation system can adapt day-to-day from collected data on day one to improve performance on day two. The platform is the CMU Iraqi-English portable two-way speechto-speech system as developed under the DARPA TransTac program. We show how machine translation, speech recognition and overall system performance can be improved on day 2 after adapting from day 1 in both a supervised and unsupervised way.","tags":null,"title":"Incremental Adaptation of Speech-to-Speech Translation","type":"publication"},{"authors":["Nguyen Bach","Qin Gao","Stephan Vogel"],"categories":null,"content":"","date":1212278400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1212278400,"objectID":"90062b6b8e8101d8e662a847af731393","permalink":"https://nguyenbh.github.io/publication/bach-gao-vogel-2008-wmt/","publishdate":"2019-10-09T21:52:00.837448Z","relpermalink":"/publication/bach-gao-vogel-2008-wmt/","section":"publication","summary":"This paper describes the statistical machine translation systems submitted to the ACL-WMT 2008 shared translation task. Systems were submitted for two translation directions: English-Spanish and Spanish-English. Using sentence pair confidence scores estimated with source and target language models, improvements are observed on the News-Commentary test sets. Genre-dependent sentence pair confidence score and integration of sentence pair confidence score into phrase table are also investigated.","tags":null,"title":"Improving Word Alignment with Language Model Based Confidence Scores","type":"publication"},{"authors":["Almut Silja Hildebrand","Kay Rottmann","Mohamed Noamany","Quin Gao","Sanjika Hewavitharana","Nguyen Bach","Stephan Vogel"],"categories":null,"content":"","date":1212278400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1212278400,"objectID":"2d0ab31b3d86a3cfc07895bf0d39b8f9","permalink":"https://nguyenbh.github.io/publication/hildebrand-et-al-2008-acl-short/","publishdate":"2019-10-09T21:52:00.839072Z","relpermalink":"/publication/hildebrand-et-al-2008-acl-short/","section":"publication","summary":"In this paper we describe recent improvements to components and methods used in our statistical machine translation system for Chinese-English used in the January 2008 GALE evaluation. Main improvements are results of consistent data processing, larger statistical models and a POS-based word reordering approach.","tags":null,"title":"Recent Improvements in the CMU Large Scale Chinese-English SMT System","type":"publication"},{"authors":["Bing Zhao","Nguyen Bach","Ian Lane","Stephan Vogel"],"categories":null,"content":"","date":1175385600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1175385600,"objectID":"44554a61a59ebe5fb4451900e4abf393","permalink":"https://nguyenbh.github.io/publication/zhao-et-al-2007-main/","publishdate":"2019-10-10T18:54:10.75239Z","relpermalink":"/publication/zhao-et-al-2007-main/","section":"publication","summary":"We propose a novel HMM-based framework to accurately transliterate unseen named entities. The framework leverages features in letter alignment and letter n-gram pairs learned from available bilingual dictionaries. Letter-classes, such as vowels/non-vowels, are integrated to further improve transliteration accuracy. The proposed transliteration system is applied to out-of-vocabulary named-entities in statistical machine translation (SMT), and a significant improvement over traditional transliteration approach is obtained. Furthermore, by incorporating an automatic spell-checker based on statistics collected from web search engines, transliteration accuracy is further improved. The proposed system is implemented within our SMT system and applied to a real translation scenario from Arabic to English.","tags":null,"title":"A Log-Linear Block Transliteration Model based on Bi-Stream HMMs","type":"publication"},{"authors":["Nguyen Bach","Sameer Badaskar"],"categories":null,"content":"","date":1167638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167638400,"objectID":"3da95c99f32e968a6739fcdd0e3a7716","permalink":"https://nguyenbh.github.io/publication/bach-badaskar-2007/","publishdate":"2019-10-02T04:12:49.356866Z","relpermalink":"/publication/bach-badaskar-2007/","section":"publication","summary":"Many applications in information extraction, natural language understanding, information retrieval require an understanding of the semantic relations between entities. We present a comprehensive review of various aspects of the entity relation extraction task. Some of the most important supervised and semi-supervised classification approaches to the relation extraction task are covered in sufficient detail along with critical analyses. We also discuss extensions to higher-order relations. Evaluation methodologies for both supervised and semi-supervised methods are described along with pointers to the commonly used performance evaluation datasets. Finally, we also give short descriptions of two important applications of relation extraction, namely question answering and biotext mining.","tags":null,"title":"A Survey on Relation Extraction","type":"publication"},{"authors":["Nguyen Bach","Mohammed Noamany","Ian Lane","Tanja Schultz"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"0eee11ad3b8f85ce44b8a8754ac97a16","permalink":"https://nguyenbh.github.io/publication/bach-2007/","publishdate":"2019-10-10T18:54:10.757922Z","relpermalink":"/publication/bach-2007/","section":"publication","summary":"We propose a novel framework to detect and recognize out-of-vocabulary (OOV) words in automated speech recognition (ASR). In the proposed framework a hybrid language model combining words and sub-word units is incorporated during ASR decoding then three different OOV words recognition methods are applied to generate OOV word hypotheses. Specifically, dictionary lookup, morphological composition, and direct phoneme-to-grapheme. The proposed approach successfully reduced WER by 1.9% and 1.6% for ASR systems with recognition vocabularies of 30K and 219K. Moreover, the proposed approach correctly recognized 5% of OOV words.","tags":null,"title":"Handling OOV Words in Arabic ASR Via Flexible Morphological Constraints","type":"publication"},{"authors":["Nguyen Bach","Matthias Eck","Paisarn Charoenpornsawat","Thilo Kohler","Sebastian Stuker","ThuyLinh Nguyen","Roger Hsiao","Alex Waibel","Stephan Vogel","Tanja Schultz","Alan Black"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"6f02d9a631a6ec4bf375f4b3e064831f","permalink":"https://nguyenbh.github.io/publication/iwslt-07-transtac/","publishdate":"2019-10-10T18:54:10.755695Z","relpermalink":"/publication/iwslt-07-transtac/","section":"publication","summary":"The paper describes our portable two-way speech-to-speech translation system using a completely eyes-free/hands-free user interface. This system translates between the language pair English and Iraqi Arabic as well as between English and Farsi, and was built within the framework of the DARPA TransTac program. The Farsi language support was developed within a 90-day period, testing our ability to rapidly support new languages. The paper gives an overview of the system’s components along with the individual component objective measures and a discussion of issues relevant for the overall usage of the system. We found that usability, flexibility, and robustness serve as severe constraints on system architecture and design.","tags":null,"title":"The CMU TransTac 2007 Eyes-free and Hands-free Two-way Speech-to-Speech Translation System","type":"publication"},{"authors":["Ian Lane","Andreas Zollmann","Thuy Linh Nguyen","Nguyen Bach","Ashish Venugopal","Stephan Vogel","Kay Rottmann","Ying Zhang","Alex Waibel"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"507d44b97f316115428b671f87666189","permalink":"https://nguyenbh.github.io/publication/iwslt-07-ukacmu-smt/","publishdate":"2019-10-10T18:54:10.760126Z","relpermalink":"/publication/iwslt-07-ukacmu-smt/","section":"publication","summary":"This paper describes the CMU-UKA statistical machine translation systems submitted to the IWSLT 2007 evaluation campaign. Systems were submitted for three language-pairs: Japanese-English, Chinese-English and Arabic-English. All systems were based on a common phrase-based SMT (statistical machine translation) framework but for each language-pair a specific research problem was tackled. For Japanese-English we focused on two problems: first, punctuation recovery, and second, how to incorporate topic-knowledge into the translation framework. Our Chinese-English submission focused on syntax augmented SMT and for the Arabic-English task we focused on incorporating morphological-decomposition into the SMT framework. This research strategy enabled us to evaluate a wide variety of approaches which proved effective for the language pairs they were evaluated on.","tags":null,"title":"The UKA-CMU Statistical Machine Translation Systems for IWSLT 2007","type":"publication"},{"authors":["Matthias Eck","Ian Lane","Nguyen Bach","Sanjika Hewavitharana","Muntsin Kolss","Bing Zhao","Almut Silja Hildebrand","Stephan Vogel","Alex Waibel"],"categories":null,"content":"","date":1136073600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136073600,"objectID":"7c2a1ca2c5c6899ae162cb63e8a254c4","permalink":"https://nguyenbh.github.io/publication/iwslt-06-ec-ukacmu-smt/","publishdate":"2019-10-10T20:52:14.500623Z","relpermalink":"/publication/iwslt-06-ec-ukacmu-smt/","section":"publication","summary":"This paper describes the UKA/CMU statistical machine translation system used in the IWSLT 2006 evaluation campaign. The system is based on phrase-to-phrase translations extracted from a bilingual corpus. We compare two different phrase alignment techniques both based on word alignment probabilities. The system was used for all language pairs and data conditions in the evaluation campaign translating both the ASR output (as 1best) and the correct recognition results.","tags":null,"title":"The UKA/CMU Statistical Machine Translation System for IWSLT 2006","type":"publication"},{"authors":["Hansjorg Mixdorff","Nguyen Bach","Hiroya Fujisaki","Mai Chi Luong"],"categories":null,"content":"","date":1041379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1041379200,"objectID":"ec32aabc4a69dfbca89fc02e545ca1a7","permalink":"https://nguyenbh.github.io/publication/mixdorff-et-al-2003/","publishdate":"2019-10-02T04:12:49.358056Z","relpermalink":"/publication/mixdorff-et-al-2003/","section":"publication","summary":"The current paper presents a preliminary study on the production and perception of syllabic tones of Vietnamese. A speech corpus consisting of fifty-two six-syllable sequences with various combinations of tones was uttered by two speakers of Standard Vietnamese, one male and one female. The corpus was labeled on the syllabic level and analyzed using the Fujisaki model. Results show that the six tone types basically fall into two categories: Level, rising, curve and falling tone can be accurately modeled by using tone commands of positive or negative polarity. The so-called drop and broken tones, however, obviously require a special control causing creaky voice and in cases a very fast drop in F0 leading to temporary F0 halving or even quartering. In contrast to the drop tone, the broken tone exhibits an F0 rise and hence a positive tone command right after the creak occurs. Further observations suggest that drop and broken tone do not only differ from the other four tones with respect to their F0 characteristics, but also as to their much tenser articulation. A perception experiment performed with natural and resynthesized stimuli shows, inter alia, that tone 4 is most prone to confusion and that tone 6 obviously requires tense articulation as well as vocal fry to be identified reliably.","tags":null,"title":"Quantitative Analysis and Synthesis of Syllabic Tones in Vietnamese","type":"publication"}]